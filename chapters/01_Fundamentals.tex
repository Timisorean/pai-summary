\section{Fundamentals}

\begin{framed}
    \begin{itemize}
        \item \textbf{Normal}:
            % $\begin{aligned}[t]
            %     &(\sqrt{2\pi \sigma^2})^{-1}\exp(-\frac{(x-\mu)^2}{2\sigma^2}) \\[-1ex]
            %     &\frac{\exp (-\frac{1}{2}(\vx - \vmu)^T \Sigma^{-1} (\vx - \vmu) )}{\sqrt{(2\pi)^k \det{\Sigma}}}
            % \end{aligned}$
             $\frac{\exp (-\frac{1}{2}(\vx - \vmu)^T \Sigma^{-1} (\vx - \vmu) )}{\sqrt{(2\pi)^k \det{\Sigma}}}$
        \item \textbf{Beta}: $\Beta[\theta]{\alpha}{\beta} \propto \theta^{\alpha-1} (1-\theta)^{\beta-1}$ 
        \item \textbf{Laplace}: $\frac{1}{2l}\exp(-\frac{\abs{x - \mu}}{l})$
    \end{itemize}
\end{framed}

\begin{itemize}
    \item Gaussian CDF has no closed-form
    \item Gaussian can be repr. using $O(n^2)$ params.; $\Sigma \in \mathbb R^{n \times n}$
\end{itemize}

\begin{framed}
    \textbf{Expectation}
    \begin{itemize}
        \item $\E{\mA \rX + \vb} = \mA \E{\rX} + \vb$;  $\E{\rX + \rY} = \E{\rX} + \E{\rY}$
        \item $\E{\rX\transpose{\rY}} = \E{\rX} \cdot \transpose{\E{\rY}}$ (if $\rX$, $\rY$ indep.)
        \item LOTUS: $\E{\vg(\rX)} = \int_{\rX(\Omega)} \vg(\vx) \cdot p(\vx) \,d\vx$ \\[-1ex]
        (if $\vg$ nice and $\rX$ cont.)
        \item Tower rule: $\E[\rY]{\E[\rX]{\rX \mid \rY}} = \E{\rX}$
    \end{itemize}
    \vspace{0.5mm}\hrule\vspace{0.5mm}
    \textbf{Variance}
    \begin{itemize}
        \item
            $\begin{aligned}[t]
                \Var{\rX} &\defeq \E{(\rX - \E{\rX})\transpose{(\rX - \E{\rX})}} \\[-1ex]
                &= \E{\rX \transpose{\rX}} - \E{\rX} \cdot \transpose{\E{\rX}} = \Cov{\rX, \rX}
            \end{aligned}$
        \item $\Var{\mA\rX + \vb} = \mA\Var{\rX}\transpose{\mA}$
        \item $\Var{\rX + \rY} = \Var{\rX} + \Var{\rY} + 2 \Cov{\rX, \rY}$
        \item $\Var{\rX + \rY} = \Var{\rX} + \Var{\rY}$ (if $\rX$, $\rY$ indep.)
        \item Law of total variance, LOTV: \\
        $\Var{\rX} = \E[\rY]{\Var[\rX]{\rX \mid \rY}} + \Var[\rY]{\E[\rX]{\rX \mid \rY}}$
    \end{itemize}
    \vspace{0.5mm}\hrule\vspace{0.5mm}
    \textbf{Covariance}
    \begin{itemize}
        \item
            $\begin{aligned}[t]
                \Cov{\rX, \rY} &\defeq \E{(\rX - \E{\rX})\transpose{(\rY - \E{\rY})}} \\[-1ex]
                &= \E{\rX \transpose{\rY}} - \E{\rX} \cdot \transpose{\E{\rY}}
            \end{aligned}$
        \item $\Cov{\rX, \rY} = \Cov{\rY, \rX}$; $\Cov{\rX, \rY} \ge \mzero$
        \item $\Cov{\mA\rX + \vc, \mB\rY + \vd} = \mA\Cov{\rX,\rY}\transpose{\mB}$
    \end{itemize}
\end{framed}

\begin{itemize}
    \item \emph{Correlation} is normalized covariance:\\
    $\Cor{\rX,\rY}(i,j) \defeq \frac{\Cov{X_i,Y_j}}{\sqrt{\Var{X_i} \Var{Y_j}}} \in [-1,1]$
    \item \emph{Uncorrelated} iff $\Cov{\rX, \rY} = \mzero$.
    \item \textbf{Change of variables:} Let $\vg$ be diff. and inv. Then for $\rY = \vg(\rX)$: $p_\rY(\vy) = p_\rX(\inv{\vg}(\vy)) \cdot \abs{\det{\jac \inv{\vg}(\vy)}}$ where $\jac \inv{\vg}(\vy)$ is the Jacobian of $\inv{\vg}$ at $\vy$.
\end{itemize}

\begin{framed}
    \textbf{Posterior} $p(\vx \mid \vy)$: updated belief about $\vx$ after observing $\vy$. \textbf{Prior} $p(\vx)$: initial belief about $\vx$. \\
    \textbf{Conditional likelihood} $p(\vy \mid \vx)$: how likely the observations $\vy$ are under a given value $\vx$. \\
    \textbf{Joint likelihood} $p(\vx, \vy) = p(\vy \mid \vx) p(\vx)$ \\
    \textbf{Marginal likelihood} $p(\vy)$: how likely the observations $\vy$ are across all values of $\vx$. Can be computed with $p(\vy) = \int_{\rX(\Omega)} p(\vy \mid \vx) \cdot p(\vx) \,d\vx$. 
\end{framed}

\begin{framed}
    \textbf{Bayes' rule}: $p(\vx \mid \vy) = \frac{p(\vy \mid \vx) \cdot p(\vx)}{p(\vy)}$
\end{framed}

\begin{itemize}
    \item If prior $p(\vx)$ and posterior $p(\vx \mid \vy)$ from same family of distr., prior is \textbf{conjugate prior} to the likelihood $p(\vy \mid \vx)$.
    \item Beta distr. is a conjugate prior to binomial likelihood.
    \item Under some conditions, the Gaussian is self-conjugate (if we have Gaussian prior and likelihood then posterior also Gaussian).
\end{itemize}

\vspace{0.5mm}\hrule\vspace{0.5mm}

\textbf{Choice of prior}
\begin{itemize}
    \item Choosing non-informative prior in absence of evidence is \textbf{principle of indifference/insufficient reason}.
    \item \textbf{Improper prior:} It is not required that the prior is a valid distr. (i.e., integrates to 1). We can still derive meaning from the posterior if its valid.
    \item \textbf{Maximum entropy principle:} choose a prior from all possible distributions that are consistent with prior knowledge, s.t. one that makes the least “additional assumptions”, i.e., the prior that is least “informative”.
\end{itemize}

\vspace{0.5mm}\hrule\vspace{0.5mm}

\textbf{Guassian properties}
\begin{itemize}
    \item Additive and closed under affine transformations.
    \item Closed under marginalization and conditioning.
\end{itemize}

\begin{framed}
    \textbf{Marginal and conditional of Normal} \\
    Let $\rX$ be Gaussian and index sets $\sA, \sB \subseteq [n]$. \\
    For any \textbf{marginal distr.} $\rX_A \sim \N{\vmu_\sA}{\mSigma_{\sA\sA}}$ and \\
    for any \textbf{conditional distr.}: \\
    $\begin{aligned}[t]
        \rX_\sA \mid \rX_\sB &= \vx_\sB \sim \N{\vmu_{\sA \mid \sB}}{\mSigma_{\sA \mid \sB}} \text{ where} \\[-1.5ex]
        \vmu_{\sA \mid \sB} &\defeq \vmu_\sA + \mSigma_{\sA\sB}\inv{\mSigma_{\sB\sB}}(\vx_\sB - \vmu_\sB) \\[-1.5ex]
        \mSigma_{\sA \mid \sB} &\defeq \mSigma_{\sA\sA} - \mSigma_{\sA\sB}\inv{\mSigma_{\sB\sB}}\mSigma_{\sB\sA}
    \end{aligned}$ \\
    Observe that the variance can only shrink.
\end{framed}

\begin{itemize}
    \item Jointly Gaussian random vectors, $\rX$ and $\rY$, are independent iff $\rX$ and $\rY$ are uncorrelated.
\end{itemize}

\columnbreak

\begin{itemize}
    \item \textbf{Heteroscedastic} noise $\vepsilon_i$ may depend on $\vx_i$, while \textbf{Homoscedastic} may not.
\end{itemize}

\vspace{0.5mm}\hrule\vspace{0.5mm}

\textbf{Maximum likelihood estimate (MLE)}: \\
\scalebox{0.9}{$\vthetahat_\MLE \defeq \underset{\vtheta \in \Theta}{\argmax} p(y_{1:n} \mid \vx_{1:n}, \vtheta) = \underset{\vtheta \in \Theta}{\argmax} \sum_{i=1}^n \log p(y_i \mid \vx_i, \vtheta)$}
\begin{itemize}
    \item \textbf{Consistent} if: $\vthetahat_\MLE \convp \opt{\vtheta}$ as $n \to \infty$.
    \item \textbf{Asymptotically normal} if $\vthetahat_\MLE \convd \N{\opt{\vtheta}}{\mS_n}$ as $n \to \infty$ where $\mathbf S_n$ is the asymptotic covariance of MLE.
    \item MLE is \textbf{asymptotically efficient} (there exists no other consistent estimator with a “smaller” asymptotic var.).
    \item For the finite sample regime the MLE need not be unbiased, and it is susceptible to overfitting to the (finite) training data.
\end{itemize}

\vspace{0.5mm}\hrule\vspace{0.5mm}

\textbf{Maximum a posterior (MAP) estimate}:\\
$\begin{aligned}[t]
\vthetahat_\MAP &\defeq \argmax_{\vtheta \in \Theta} p(\vtheta \mid \vx_{1:n}, y_{1:n}) \\
&= \argmin_{\vtheta \in \Theta} \underbrace{- \log p(\vtheta)}_{\text{regularization}} + \underbrace{\ell_\mathrm{nll}(\vtheta; \spD_n)}_{\text{quality of fit}}
\end{aligned}$\\
The \textbf{log-prior} $\log p(\vtheta)$ acts as a regularize. Common:
\begin{itemize}
    \item $p(\vtheta) = \N[\vtheta]{\vzero}{\lambda \mI}$ gives $-\log p(\vtheta) = \frac{\lambda}{2} \norm{\vtheta}_2^2 + \const$
    \item $p(\vtheta) = \Laplace[\vtheta]{\vzero}{\lambda}$ gives $-\log p(\vtheta) = \lambda \norm{\vtheta}_1 + \const$
    \item  Uniform prior gives $\const$ (no regularization, MAP is equivalent to the MLE)
\end{itemize}

\begin{framed}
     \textbf{Expected calibration error}: For $m$ bins: $\ell_{\mathrm{ECE}} \defeq \sum_{m=1}^M \frac{\card{\sB_m}}{n} \abs{\mathrm{freq}(\sB_m) - \mathrm{conf}(\sB_m)}$
\end{framed}
