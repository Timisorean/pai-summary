\vspace{0.5mm}\hrule\vspace{0.5mm}
\section{Markov Chains (MCs)}

\begin{framed}
    A seq. $(X_t)_{t \in \Nat_0} \in \sS$ with $\sS \defeq \{0, \dots, n-1\}$, s.t. the \textbf{Markov property}: $X_{t+1} \perp X_{0:t-1} \mid X_t$ is satisfied. 
\end{framed}

\begin{itemize}
    \item It is \textbf{time-homogeneous} if there is a \textbf{transition fn.}: $p(x' \mid x) \defeq \Pr{X_{t+1} = x' \mid X_t = x}$, with \textbf{transition mat.} as $(x_j \mid x_i)_{i, j = 1}^n$ and each row sums up to 1. \vspace{-1ex}
    % \item The state of a MC at $t$ is a prob. distr. $\vq_t \in \R^{1 \times \card{\sS}}$. We can write: $\vq_{t+k} = \vq_t \mP^k$.
\end{itemize}

\begin{framed}
    A distribution $\pi$ is \textbf{stationary} iff\\
    $\pi(x) = \sum_{x' \in S} p(x \mid x') \pi(x')$ equivalently $\vpi = \vpi \mP$.
\end{framed}

\begin{itemize}
    \item A MC is \textbf{irreducible} if every state is reachable from any state with positive probability.
    \item A MC is \textbf{ergodic} iff there exists a $t \in \Nat_0$ s.t for any\\[-0.5ex]
    $x, x' \in S$ we have: $p^{(t)}(x' \mid x) > 0$. Equivalently: for\\[-0.7ex]
    some $t \in \Nat_0$ all entries of $\mP^t$ are strictly positive or that the MC is irreducible and aperiodic.
    % \item Irreducible MC $\rightarrow$ ergodic MC use: $\mP' = \frac{1}{2}\mP + \frac{1}{2}\mI$
    % \item An ergodic MC has a unique stat. dist. $\pi$ (with full support) and $\lim_{t\to\infty} q_t = \pi$, independently of $q_0$.
\end{itemize}

\begin{framed}
    A MC satisfies the \textbf{detailed balance equation} w.r.t. $\pi$ iff $\pi(x) p(x' \mid x) = \pi(x') p(x \mid x')$, for any $x, x' \in S$. We call such a MC \textbf{reversible} w.r.t. $\pi$.
\end{framed}

\begin{itemize}
    % \item If MC is reversible w.r.t. $\pi$, then $\pi$ is a stat. dist.

% \begin{framed}
%     \textbf{Ergodic theorem} For an ergodic MC and a stat. dist. $\pi$ as well as $f : \sS \to \R$:
%     $\frac{1}{n} \sum_{i=1}^n f(x_i) \almostsurely \sum_{x \in S} \pi(x) f(x) = \E[x \sim \pi]{f(x)}$, for $n\to\infty$ where $x_i \sim X_i \mid x_{i-1}$.
% \end{framed}

% \textbf{Acceptance distribution (Metropolis-Hastings)}: $\Bern{\alpha(\vxp \mid \vx)}$ where $\alpha(\vxp \mid \vx) \defeq \min \braces*{1, \frac{q(\vxp) r(\vx \mid \vxp)}{q(\vx) r(\vxp \mid \vx)}}$ to decide whether to follow the proposal yields a Markov chain with stationary distribution $p(\vx) = \frac{1}{Z} q(\vx)$.
% \includegraphics[width=0.98\linewidth, trim={0 0 5cm 0}]{images/Metropiolis_Hasting.png}
% \includegraphics[width=0.98\linewidth]{images/Gibbs_Sampling.png} 

    % \item The stationary distr. of the simulated MC is $p(\vx)$.
    \item A \textbf{Gibbs distr.} is a cont. distr. $p$ whose PDF has form $p(\vx) = \frac{1}{Z} \exp(- f(\vx))$. $f$ is also called an \textbf{energy fn.}.
    %When $f$ is convex, its Gibbs distr. is called \textbf{log-concave distribution}. 
    %Can write: $\alpha(\vxp \mid \vx) = \min \braces*{1, \frac{r(\vx \mid \vxp)}{r(\vxp \mid \vx)} \exp(f(\vx) - f(\vxp))}$. \\
    % For $p(\vx) \propto \exp(-f(\vx))$: $\S{p(\vx)} = f(\vx) + \log Z$
\end{itemize}

% \begin{framed}
%     \textbf{Langevin Dynamics}: Shift the proposal distribution perpendicularly to the gradient of the energy function: $r(\vxp \mid \vx) = \N[\vxp]{\vx - \eta_t \grad f(\vx)}{2 \eta_t \mI}$.
% \end{framed}
